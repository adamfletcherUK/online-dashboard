# Data Engineering

-	Migrating Jupyter notebooks to production CI/CD data pipelines, complete with ETL, feature engineering, model training, deployment, and performance reporting.
-	Deploying production ML APIs with multiple endpoints, serving model predictions for different purposes.
-	Building simple data lakes on AWS and using AWS Glue crawlers to query multiple files and databases.
-	Utilising frameworks like Dask and cuDF to parallelize and speed up computation time on large datasets.
-	Experience using: Python, Jupyter, R, SQL, Shell, Tensorflow, Git, docker, Dask, Flask, Travis, AWS & Heroku. 